{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-IqJAMkwnCF"
   },
   "source": [
    "# Advanced Retrieval with LangChain\n",
    "\n",
    "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
    "\n",
    "We'll touch on:\n",
    "\n",
    "- Naive Retrieval\n",
    "- Best-Matching 25 (BM25)\n",
    "- Multi-Query Retrieval\n",
    "- Parent-Document Retrieval\n",
    "- Contextual Compression (a.k.a. Rerank)\n",
    "- Ensemble Retrieval\n",
    "- Semantic chunking\n",
    "\n",
    "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
    "\n",
    "There will be two breakout rooms:\n",
    "\n",
    "- 🤝 Breakout Room Part #1\n",
    "  - Task 1: Getting Dependencies!\n",
    "  - Task 2: Data Collection and Preparation\n",
    "  - Task 3: Setting Up QDrant!\n",
    "  - Task 4-10: Retrieval Strategies\n",
    "- 🤝 Breakout Room Part #2\n",
    "  - Activity: Evaluate with Ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rKP3hgHivpe"
   },
   "source": [
    "# 🤝 Breakout Room Part #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xes8oT-xHN7"
   },
   "source": [
    "## Task 1: Getting Dependencies!\n",
    "\n",
    "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkgFAXWVW3wm",
    "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.0.1 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\n",
      "ragas 0.1.20 requires langchain-core<0.3, but you have langchain-core 0.3.7 which is incompatible.\n",
      "grpcio-status 1.66.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKqYM4Eoxcov"
   },
   "source": [
    "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "s6xav5CxYnML"
   },
   "outputs": [],
   "source": [
    "!pip install -qU qdrant-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7OHJXzfyJyA"
   },
   "source": [
    "We'll also provide our OpenAI key, as well as our Cohere API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LttlDQUYgSI",
    "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iUahNiJyQbv",
    "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw304iAFyRtl"
   },
   "source": [
    "## Task 2: Data Collection and Preparation\n",
    "\n",
    "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
    "\n",
    "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXKHcZmKzDwT"
   },
   "source": [
    "### Data Collection\n",
    "\n",
    "We can simply `wget` these from GitHub.\n",
    "\n",
    "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbbSIGtzX3dS",
    "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
    "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
    "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
    "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A92NC2QZzCsi"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
    "\n",
    "- Self-Query: Wants as much metadata as we can provide\n",
    "- Time-weighted: Wants temporal data\n",
    "\n",
    "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "GshBjVRJZ6p8"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "documents = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "  loader = CSVLoader(\n",
    "      file_path=f\"john_wick_{i}.csv\",\n",
    "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
    "  )\n",
    "\n",
    "  movie_docs = loader.load()\n",
    "  for doc in movie_docs:\n",
    "\n",
    "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
    "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
    "\n",
    "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
    "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
    "\n",
    "    # newer movies have a more recent \"last_accessed_at\"\n",
    "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
    "\n",
    "  documents.extend(movie_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gQphb6y0C0S"
   },
   "source": [
    "Let's look at an example document to see if everything worked as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkUkCf7DaMiq",
    "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2024, 9, 27, 23, 12, 59, 674708)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWaQpdHl0Gzc"
   },
   "source": [
    "## Task 3: Setting up QDrant!\n",
    "\n",
    "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
    "\n",
    "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
    "\n",
    "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "NT8ihRJbYmMT"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"JohnWick\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2SS4Rh0hiN"
   },
   "source": [
    "## Task 4: Naive RAG Chain\n",
    "\n",
    "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEH7X5Ai08FH"
   },
   "source": [
    "### R - Retrieval\n",
    "\n",
    "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
    "\n",
    "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "GFDPrNBtb72o"
   },
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbBhyQjz06dx"
   },
   "source": [
    "### A - Augmented\n",
    "\n",
    "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "7uSz-Dbqcoki"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlRzpb231GGJ"
   },
   "source": [
    "### G - Generation\n",
    "\n",
    "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "c-1t9H60dJLg"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg3QRGzA1M2x"
   },
   "source": [
    "### LCEL RAG Chain\n",
    "\n",
    "We're going to use LCEL to construct our chain.\n",
    "\n",
    "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "0bvstS7mdOW3"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "naive_retrieval_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izKujhNb1ZG8"
   },
   "source": [
    "Let's see how this simple chain does on a few different prompts.\n",
    "\n",
    "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LI-5ueEddku9",
    "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, people generally liked John Wick based on the positive reviews provided.'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "43zdcdUydtXh",
    "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there is a review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'\""
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "lpG6rlvvvKFq",
    "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In John Wick, an ex-hitman comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. This leads to a series of violent confrontations and action-packed sequences as John Wick navigates a world of assassins and criminals.'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsbfQmbr1leg"
   },
   "source": [
    "Overall, this is not bad! Let's see if we can make it better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft1vt8HPR16w"
   },
   "source": [
    "## Task 5: Best-Matching 25 (BM25) Retriever\n",
    "\n",
    "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
    "\n",
    "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
    "\n",
    "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "qdF4wuj5R-cG"
   },
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIjJlBQ8drKH"
   },
   "source": [
    "We'll construct the same chain - only changing the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "WR15EQG7SLuw"
   },
   "outputs": [],
   "source": [
    "naive_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Gi-yXCDdvJk"
   },
   "source": [
    "Let's look at the responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "oY9qzmm3SOrF",
    "outputId": "4d4f450f-5978-460f-f242-b32407868353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Opinions on John Wick seem to be divided based on the reviews provided. Some people really enjoyed the movie and found it to be a must-see for action fans, while others found it to be lacking in plot and substance. So, it's safe to say that not everyone liked John Wick.\""
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "igfinyneSQkh",
    "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "w0H7pV_USSMQ",
    "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Wick is an action movie with beautifully choreographed scenes and emotional setup. It stars Keanu Reeves and is highly recommended for action movie lovers.'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvg5xHaUdxCl"
   },
   "source": [
    "It's not clear that this is better or worse - but the `I don't know` isn't great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-dcbFn2vpZF"
   },
   "source": [
    "## Task 6: Contextual Compression (Using Reranking)\n",
    "\n",
    "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
    "\n",
    "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
    "\n",
    "The basic idea here is this:\n",
    "\n",
    "- We retrieve lots of documents that are very likely related to our query vector\n",
    "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
    "\n",
    "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
    "\n",
    "All we need to do is the following:\n",
    "\n",
    "- Create a basic retriever\n",
    "- Create a compressor (reranker, in this case)\n",
    "\n",
    "That's it!\n",
    "\n",
    "Let's see it in the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "psHvO2K1v_ZQ"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=naive_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TA9RB2x-j7P"
   },
   "source": [
    "Let's create our chain again, and see how this does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "1BXqmxvHwX6T"
   },
   "outputs": [],
   "source": [
    "contextual_compression_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "V3iGpokswcBb",
    "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, people generally liked John Wick based on the positive reviews and high ratings it received.'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "7u_k0i4OweUd",
    "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there is a review with a rating of 10. Here is the URL to that review:\\n- Review URL: '/review/rw4854296/?ref_=tt_urv'\""
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "zn1EqaGqweXN",
    "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In John Wick 2, after resolving his issues with the Russian mafia, John Wick is asked by Santino D'Antonio to kill his sister Gianna D'Antonio in Rome. When John completes the assignment, Santino puts a seven-million dollar contract on him, leading to professional killers coming after him. Wick promises to kill Santino, who is not protected by his marker anymore.\""
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEbT0g2S-mZ4"
   },
   "source": [
    "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqbghrBEQNn5"
   },
   "source": [
    "## Task 7: Multi-Query Retriever\n",
    "\n",
    "Typically in RAG we have a single query - the one provided by the user.\n",
    "\n",
    "What if we had....more than one query!\n",
    "\n",
    "In essence, a Multi-Query Retriever works by:\n",
    "\n",
    "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
    "2. Retrieving documents for each query.\n",
    "3. Using all unique retrieved documents as context\n",
    "\n",
    "So, how is it to set-up? Not bad! Let's see it down below!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "pfM26ReXQjzU"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=naive_retriever, llm=chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "1vRc129jQ5WW"
   },
   "outputs": [],
   "source": [
    "multi_query_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "CGgNuOb3Q3M9",
    "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, people generally liked John Wick based on the reviews provided.'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "aAlSthxrRDBC",
    "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, there are no reviews with a rating of 10 for the movie \"John Wick 4.\"'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "Uv1mpCK8REs4",
    "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In John Wick, the main character, played by Keanu Reeves, is a retired assassin who is forced back into action when his car is stolen, leading to a lot of carnage. He is also called upon to pay off an old debt by helping take over the Assassin's Guild in various locations by killing many assassins.\""
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDEawBf_d_3G"
   },
   "source": [
    "## Task 8: Parent Document Retriever\n",
    "\n",
    "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
    "\n",
    "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
    "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
    "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
    "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
    "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
    "\n",
    "Okay, maybe that was a few steps - but the basic idea is this:\n",
    "\n",
    "- Search for small documents\n",
    "- Return big documents\n",
    "\n",
    "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
    "\n",
    "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "qJ53JJuMd_ZH"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "parent_docs = documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOpXfVUH3gL3"
   },
   "source": [
    "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
    "\n",
    "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzFc-_9HlGQ-",
    "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
   },
   "outputs": [],
   "source": [
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"full_documents\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "parent_document_vectorstore = Qdrant(\n",
    "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf_g95FA3s6w"
   },
   "source": [
    "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "BpWVjPf4fLUp"
   },
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore = parent_document_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoYmSWfE32Zo"
   },
   "source": [
    "By default, this is empty as we haven't added any documents - let's add some now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "iQ2ZzfKigMZc"
   },
   "outputs": [],
   "source": [
    "parent_document_retriever.add_documents(parent_docs, ids=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI7Tip1335rE"
   },
   "source": [
    "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "Qq_adt2KlSqp"
   },
   "outputs": [],
   "source": [
    "parent_document_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNolUVQb4Apt"
   },
   "source": [
    "Let's give it a whirl!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "TXB5i89Zly5W",
    "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the reviews provided, opinions on John Wick seem to be divided. Some people love the series, while others have strong negative opinions about it.'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "V5F1T-wNl3cg",
    "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3\". The URL to that review is \\'/review/rw4854296/?ref_=tt_urv\\'.'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "ZqARszGzvGcG",
    "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In John Wick, Keanu Reeves plays the character John Wick, a retired assassin who comes out of retirement after someone kills his dog. In the sequel, John Wick 2, he is called on to pay off an old debt by helping take over the Assassin's Guild by traveling to Italy, Canada, and Manhattan and killing many assassins.\""
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B41cj42s4DPM"
   },
   "source": [
    "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUrIBKl_TwS9"
   },
   "source": [
    "## Task 9: Ensemble Retriever\n",
    "\n",
    "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
    "\n",
    "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
    "\n",
    "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "8j7jpZsKTxic"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
    "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retriever_list, weights=equal_weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpo9Psl5hhJ-"
   },
   "source": [
    "We'll pack *all* of these retrievers together in an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "KZ__EZwpUKkd"
   },
   "outputs": [],
   "source": [
    "ensemble_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSsvHpRMj24L"
   },
   "source": [
    "Let's look at our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "0lMvqL88UQI-",
    "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, people generally liked John Wick based on the reviews provided.'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "MNFWLYECURI1",
    "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a review with a rating of 10 for \"John Wick 3\". Here is the URL to that review: /review/rw4854296/?ref_=tt_urv'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "A7qbHfWgUR4c",
    "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In John Wick, an ex-hitman comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. The story involves a lot of violence, shootouts, and breathtaking fights as John Wick faces off against various enemies.'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MopbkNJAXVaN"
   },
   "source": [
    "## Task 10: Semantic Chunking\n",
    "\n",
    "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
    "\n",
    "Essentially, Semantic Chunking is implemented by:\n",
    "\n",
    "1. Embedding all sentences in the corpus.\n",
    "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
    "  - `percentile`\n",
    "  - `standard_deviation`\n",
    "  - `interquartile`\n",
    "  - `gradient`\n",
    "3. Each sequence of related sentences is kept as a document!\n",
    "\n",
    "Let's see how to implement this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dHeB-yGXneL",
    "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9ciZbFEldv_"
   },
   "source": [
    "We'll use the `percentile` thresholding method for this example which will:\n",
    "\n",
    "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "66EIEWiEYl5y"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqoKmz12mhRW"
   },
   "source": [
    "Now we can split our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "ROcV7o68ZIq7"
   },
   "outputs": [],
   "source": [
    "semantic_documents = semantic_chunker.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8-LNC-Xmjex"
   },
   "source": [
    "Let's create a new vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "h3sl9QjyZhIe"
   },
   "outputs": [],
   "source": [
    "semantic_vectorstore = Qdrant.from_documents(\n",
    "    semantic_documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"JohnWickSemantic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh_r_-LHmmKn"
   },
   "source": [
    "We'll use naive retrieval for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "odVyDUHwZftc"
   },
   "outputs": [],
   "source": [
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkeiv_ojmp6G"
   },
   "source": [
    "Finally we can create our classic chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "xWE_0J0mZveG"
   },
   "outputs": [],
   "source": [
    "semantic_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5pfjLQ3ms9_"
   },
   "source": [
    "And view the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "0lN2j-e4Z0SD",
    "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, people generally liked John Wick based on the reviews provided.'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "xdqfBH1SZ3f9",
    "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there is a review with a rating of 10. Here is the URL to that review:\\n- Review_URL: '/review/rw4854296/?ref_=tt_urv'\""
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "rAcAObZnZ4o6",
    "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Wick is a movie about an ex-hitman who comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. The movie is known for its violent and gripping story with plenty of action, shootouts, and breathtaking fights.'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk2n3-pnVWDJ"
   },
   "source": [
    "# 🤝 Breakout Room Part #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SkJLYwMVZkj"
   },
   "source": [
    "#### 🏗️ Activity #1\n",
    "\n",
    "Your task is to evaluate the various Retriever methods against eachother.\n",
    "\n",
    "You are expected to:\n",
    "\n",
    "1. Create a \"golden dataset\"\n",
    " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
    "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
    " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
    "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
    "\n",
    "Your analysis should factor in:\n",
    "  - Cost\n",
    "  - Latency\n",
    "  - Performance\n",
    "\n",
    "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWAr16a5XMub"
   },
   "source": [
    "##### HINTS:\n",
    "\n",
    "- LangSmith provides detailed information about latency and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "tgDICngKXLGK"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Advanced RAG - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "documents = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "  loader = CSVLoader(\n",
    "      file_path=f\"john_wick_{i}.csv\",\n",
    "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
    "  )\n",
    "\n",
    "  movie_docs = loader.load()\n",
    "  for doc in movie_docs:\n",
    "\n",
    "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
    "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
    "\n",
    "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
    "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
    "\n",
    "    # newer movies have a more recent \"last_accessed_at\"\n",
    "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
    "\n",
    "  documents.extend(movie_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2024, 9, 27, 23, 15, 6, 833281)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores  import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"JohnWick\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "naive_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU pymupdf ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_google_vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in _VertexAIBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in _VertexAICommon has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/ragas/metrics/__init__.py:8: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from ragas.metrics._context_entities_recall import (\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c795f549544e8bb48aa7da34252f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[292], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testset \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mgenerate_with_langchain_docs(documents, \u001b[38;5;241m20\u001b[39m, distributions, with_debugging_logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/testset/generator.py:206\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    204\u001b[0m distributions \u001b[38;5;241m=\u001b[39m distributions \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39madd_documents(\n\u001b[1;32m    207\u001b[0m     [Document\u001b[38;5;241m.\u001b[39mfrom_langchain_document(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    208\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    211\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size,\n\u001b[1;32m    212\u001b[0m     distributions\u001b[38;5;241m=\u001b[39mdistributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/testset/docstore.py:214\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_documents\u001b[0;34m(self, docs, show_progress)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# split documents with self.splitter into smaller nodes\u001b[39;00m\n\u001b[1;32m    210\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    211\u001b[0m     Node\u001b[38;5;241m.\u001b[39mfrom_langchain_document(d)\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39mtransform_documents(docs)\n\u001b[1;32m    213\u001b[0m ]\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_nodes(nodes, show_progress\u001b[38;5;241m=\u001b[39mshow_progress)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/testset/docstore.py:253\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_nodes\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    251\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nodes_to_embed\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(documents, 20, distributions, with_debugging_logs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4d2e1b899e45dc8a28a0844504fd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 0: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cefa954a0dc4984af5f7124d9d14313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 1: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a6958a333e46768d5d4d04c7559981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 2: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2add90db021c4e44ab19ff289e3163d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 3: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ab6fc2d40f42b8b2e568406aa6193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 4: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be94e75eb9843448019aafa38e20092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 5: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b902ffcaf6cd4ce0b4c9f4c9ad514cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 6: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f3b8f91fac42528d0b9a04b127a3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 7: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e2a71d4d124cf7a5109964a3864c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 8: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d581bcdd72342aaa7a137adc7bfa68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 9: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b033ce577f648bd8ec5212d4468f8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 10: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6744c5c7e8724b99a11268397ef275f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 11: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3319a072842b4fada0360ed9877f9971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 12: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bba15766f47475dbd92c69e012db684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 13: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82933acb0ff843c994ed3c8c6114f664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 14: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd9d1e3800e41ef8961cfdd803358f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 15: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbdec6a1e42490788296674e67906a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 16: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9974146903429d846c3d54ce899e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 17: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0f6b44f91c41babed12fb67cb046df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 18: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df51053684644f19e482a3e380b3e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 19: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145f822a439c46db995a5fc89f4bc38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 20: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da74a1d7317401282d053aec839e575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 21: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139e4ccc296441fbb5fcf6ec50028b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 22: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b14bee8b1842b8b5356977ec570c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 23: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3339914e233c4233b7427c846f0069a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 24: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b86697ff7394a3db8772ba0174c8b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 25: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4980153067457f9667976347768b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 26: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d044cb123d49618d64426267bf34b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 27: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811e8862a0504668b35986604b7f8559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 28: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec119a4c843f47e885c5f8f1095992f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 29: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e7b8f070cd41158570032290ab9c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 30: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e3414f789b4494b1f4fb4a24af724d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 31: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e6b380368a4f93b17bd99a78a393dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 32: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b7f9d36dd04509b428979f8b313287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 33: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5c5ea1f43f438fa12352a444fdfd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 34: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d635f4e6336a4adda935b6e83095b2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 35: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1575a9e68e0d4587b3c0b6e27379e48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 36: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ab9c2244f1407a98e7c60e1212b57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 37: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe08a5a244e14ec0b1ac3efda1054fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 38: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61327003d47b4e9580d056cde63c20cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 39: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92595e7e597245308befcc61a48d6b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 40: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b4645515c84238924123d892553913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 41: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392d7c137fd9461e88295b4ee3b1aebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 42: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d335002a3f444ac0ad26ce4889768a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 43: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c1464e870d43a5b72fd15f0e84ae8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 44: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1790887c2b40eabaf32a4ac0684418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 45: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbffefdc29624f23a6de7125c145255c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 46: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd7e9a48e854f72a34961e86e432389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 47: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328bc4a358a9458482af7985beb66fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 48: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c018051e405947f39ccc7b16de3a024f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 49: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f95d04a4beb4ab9bc059b2a667cc069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 50: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c3716a2d0e401b9b8d31ad20bcf198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 51: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11addb7ed14e4e058c8ab43f83e9d546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 52: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec8e374bbe452eb7a11e35a4c82e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 53: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b013758594824280a9a763cbe9ff1626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 54: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db99444b01574600a966623ade548ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 55: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30141d082e19404b9381c85ec56d2195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 56: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b3e61f20ea476184c4c9c26f1b55b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 57: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9194495d61394a568565b3cc82892ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 58: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac32d8ad952f477383ea194836a8a82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 59: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f043579c9a8645699627a8b3db83d6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 60: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b312c553b2469197f5803032fc0b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 61: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90a8d187f614ca486634e0f4c286d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 62: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cd63d218e445dcb61c5c03c99dd1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 63: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ec6aa47a5e4802bcdfb5647a687b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 64: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf907ac89cc40edba14d244e12a3db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 65: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c01ef38850b42ad91867167fe79d125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 66: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66cdf0ca38640628bbbf91293172490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 67: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32af014b1a094128aca5ceeb99a69b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 68: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1828b26cf5da4befa0a1368a7cd9733d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 69: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2521239eef04d789ce259938371903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 70: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3acd38baed49d1bf3d2eb2782fdbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 71: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e863b341a9d48a883ff16374a8ad209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 72: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba2487b58884f7bbe22a64dcf09b3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 73: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ae03db7e7a4b949c8f7b8b742b9f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 74: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1302eb65284052a68c021bdfada7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 75: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9e06b89a704ec4a69f6be2e7b4fd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 76: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b1b9574cf3474c8929bedd21eb45cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 77: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b54217cfc354e0d95a7455b01f80b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 78: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15517e61b67848608e3353fb1c4acdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 79: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58ab1a8a3c84613ab533934eb21564e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 80: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bd56d2d09f4708b5363eb735c64a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 81: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde29d281c7a4848b6b6a58ac2f55fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 82: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bd1f0be84f467b9711fadad3758535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 83: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649ce66456c44a7186be76b40339adfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 84: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0876b1f46fd24351b01412440f6ed6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 85: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203472619d084ef2992e320d9d037664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 86: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896ea9719078454e8739cbebae4eb9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 87: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ec8b18eb6b49c1b468ac7e15ab3a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 88: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bf23f756ff494b9d41cd3ea2b20ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 89: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8799bdafc40f4973984cbe37e3696be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 90: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323d9e95823849e2a6bf749988194e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 91: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8e1cb4f3c9445fa7517d1488653cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 92: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d74b6111ab423990aadad78116db68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 93: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd04a923828247e3bf0403d50ed0fc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 94: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03b324b6a14407dad2d5f52c6fcf16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 95: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a97dab602e4235b410a01e32de062b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 96: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0b40bbc6084504b0c31852d67a79c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 97: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bc82225327447ba3dd5afd88354107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 98: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd7583c0467404582ef0fc5ceac0166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with document 99: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    try:\n",
    "        testset = generator.generate_with_langchain_docs(\n",
    "            [doc],  # Process one document at a time\n",
    "            1, \n",
    "            distributions, \n",
    "            with_debugging_logs=True, \n",
    "            raise_exceptions=True\n",
    "        )\n",
    "        print(f\"Document {i} processed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with document {i}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents, \n",
    "    20, \n",
    "    distributions, \n",
    "    with_debugging_logs=True, \n",
    "    raise_exceptions=True, \n",
    "    is_async=False  # Disable async execution to simplify debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in /opt/anaconda3/lib/python3.12/site-packages (0.1.20)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain_community in /opt/anaconda3/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (1.26.4)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (3.0.1)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (0.7.0)\n",
      "Collecting langchain-core<0.3 (from ragas)\n",
      "  Using cached langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (0.2.1)\n",
      "Requirement already satisfied: openai>1 in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (1.50.2)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (0.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /opt/anaconda3/lib/python3.12/site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Using cached langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Using cached langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.1.129)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.3->ragas) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.3->ragas) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.3->ragas) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai>1->ragas) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai>1->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai>1->ragas) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai>1->ragas) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai>1->ragas) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas) (0.70.17)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->ragas) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas) (0.25.1)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai (from ragas)\n",
      "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken->ragas) (2023.10.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3->ragas) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->ragas)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets->ragas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets->ragas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n",
      "Using cached langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.2.17-py3-none-any.whl (2.3 MB)\n",
      "Using cached langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "Using cached langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Using cached langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Installing collected packages: dill, multiprocess, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain_community\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.17\n",
      "    Uninstalling multiprocess-0.70.17:\n",
      "      Successfully uninstalled multiprocess-0.70.17\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.7\n",
      "    Uninstalling langchain-core-0.3.7:\n",
      "      Successfully uninstalled langchain-core-0.3.7\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.0\n",
      "    Uninstalling langchain-text-splitters-0.3.0:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.0\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.2.1\n",
      "    Uninstalling langchain-openai-0.2.1:\n",
      "      Successfully uninstalled langchain-openai-0.2.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.1\n",
      "    Uninstalling langchain-0.3.1:\n",
      "      Successfully uninstalled langchain-0.3.1\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.3.1\n",
      "    Uninstalling langchain-community-0.3.1:\n",
      "      Successfully uninstalled langchain-community-0.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.0 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.2.41 which is incompatible.\n",
      "langchain-cohere 0.3.0 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.2.41 which is incompatible.\n",
      "langchain-experimental 0.3.2 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.2.17 which is incompatible.\n",
      "langchain-experimental 0.3.2 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.2.41 which is incompatible.\n",
      "langchain-google-vertexai 2.0.2 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.2.41 which is incompatible.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dill-0.3.8 langchain-0.2.16 langchain-core-0.2.41 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langchain_community-0.2.17 multiprocess-0.70.16\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ragas langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c2a4fd7cb42999c962e504e9be1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[307], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testset \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mgenerate_with_langchain_docs(documents, \u001b[38;5;241m20\u001b[39m, distributions, with_debugging_logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/testset/generator.py:206\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    204\u001b[0m distributions \u001b[38;5;241m=\u001b[39m distributions \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39madd_documents(\n\u001b[1;32m    207\u001b[0m     [Document\u001b[38;5;241m.\u001b[39mfrom_langchain_document(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    208\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    211\u001b[0m     test_size\u001b[38;5;241m=\u001b[39mtest_size,\n\u001b[1;32m    212\u001b[0m     distributions\u001b[38;5;241m=\u001b[39mdistributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/testset/docstore.py:214\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_documents\u001b[0;34m(self, docs, show_progress)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# split documents with self.splitter into smaller nodes\u001b[39;00m\n\u001b[1;32m    210\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    211\u001b[0m     Node\u001b[38;5;241m.\u001b[39mfrom_langchain_document(d)\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39mtransform_documents(docs)\n\u001b[1;32m    213\u001b[0m ]\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_nodes(nodes, show_progress\u001b[38;5;241m=\u001b[39mshow_progress)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/testset/docstore.py:253\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.add_nodes\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    251\u001b[0m results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nodes_to_embed\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(documents, 20, distributions, with_debugging_logs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain API Key: ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your langsmith key is: AIE4 - A14 - BM25 bbaa6be0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import os\n",
    "# from uuid import uuid4\n",
    "\n",
    "\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
    "\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE4 - A14 - BM25 {uuid4().hex[0:8]}\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# print(f\"Your langsmith key is: {os.environ['LANGCHAIN_PROJECT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.environ.get(\"COHERE_API_KEY\")\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Advanced RAG - {unique_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='In \"John Wick,\" John\\'s dog dies.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 3908, 'total_tokens': 3918, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-2150a815-cf77-48bc-b8aa-e6c1f8fed216-0' usage_metadata={'input_tokens': 3908, 'output_tokens': 10, 'total_tokens': 3918}\n",
      "In \"John Wick,\" John's dog dies.\n"
     ]
    }
   ],
   "source": [
    "response = naive_retrieval_chain.invoke({\"question\" : \"Who dies in John Wick?\"})['response']\n",
    "print(response)\n",
    "print(response.content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "599\n",
      "Average Content Length: 533.9\n",
      "Minimum Content Length: 29\n",
      "Maximum Content Length: 2440\n"
     ]
    }
   ],
   "source": [
    "documents[0]\n",
    "print(len(documents))\n",
    "content_1 = documents[0].page_content\n",
    "print(len(content_1))\n",
    "lengths = [len(doc.page_content) for doc in documents]\n",
    "average_length = sum(lengths) / len(lengths) if lengths else 0\n",
    "min_length = min(lengths) if lengths else 0\n",
    "max_length = max(lengths) if lengths else 0\n",
    "\n",
    "print(f\"Average Content Length: {average_length}\")\n",
    "print(f\"Minimum Content Length: {min_length}\")\n",
    "print(f\"Maximum Content Length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "import pickle\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "file_path = 'ragas_testset.pkl'\n",
    "\n",
    "# load an existing ragas testset\n",
    "def load_ragas_testset_if_exists():\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                ragas_state = pickle.load(f)\n",
    "            print(f\"Ragas testset loaded from {file_path}\")\n",
    "            return ragas_state\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ragas testset: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"No existing ragas tesetset found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Save the ragas testset\n",
    "def save_ragas_testset(testset):\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(testset, f)\n",
    "        print(f\"Ragas testset saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving ragas testset: {e}\")\n",
    "\n",
    "\n",
    "# create questions\n",
    "def create_questions_for_ragas(documents, num_questions=1):\n",
    "    generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    generator = TestsetGenerator.from_langchain(\n",
    "        generator_llm,\n",
    "        critic_llm,\n",
    "        embeddings\n",
    "    )\n",
    "    distributions = {\n",
    "        simple: 0.5,\n",
    "        multi_context: 0.4,\n",
    "        reasoning: 0.1\n",
    "    }\n",
    "    \n",
    "    testset = generator.generate_with_langchain_docs(documents, num_questions, distributions, with_debugging_logs=False)\n",
    "    save_ragas_testset(testset)\n",
    "    return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas testset loaded from ragas_testset.pkl\n"
     ]
    }
   ],
   "source": [
    "create_questions = False\n",
    "ragas_testset = None\n",
    "num_questions = 40\n",
    "if create_questions:\n",
    "    ragas_testset = create_questions_for_ragas(documents, num_questions)\n",
    "else:\n",
    "    ragas_testset = load_ragas_testset_if_exists()\n",
    "if ragas_testset:\n",
    "    ragas_testset.to_pandas()\n",
    "else:\n",
    "    print(\"No RAGAS testset found - need to create questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = ragas_testset.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What makes John Wick stand out as a favorite r...</td>\n",
       "      <td>[: 22\\nReview: John Wick is one of my favourit...</td>\n",
       "      <td>John Wick stands out as a favorite recent year...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 22, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some examples of classic internationa...</td>\n",
       "      <td>[: 11\\nReview: JOHN WICK is a rare example of ...</td>\n",
       "      <td>Some examples of classic international films s...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 11, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the surprise hit movie starring Keanu...</td>\n",
       "      <td>[: 6\\nReview: In 2014, a Keanu Reeves revenge ...</td>\n",
       "      <td>John Wick</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 6, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who does John Wick face as he is called upon b...</td>\n",
       "      <td>[: 5\\nReview: Iosef's uncle still has John Wic...</td>\n",
       "      <td>John Wick faces deadly assassins, numerous kil...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_2.csv', 'row': 5, 'Revi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the genre and main actor of the film \"...</td>\n",
       "      <td>[: 21\\nReview: John Wick is an action film wit...</td>\n",
       "      <td>The genre of the film 'John Wick' is action, a...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'john_wick_1.csv', 'row': 21, 'Rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What makes John Wick stand out as a favorite r...   \n",
       "1  What are some examples of classic internationa...   \n",
       "2  What was the surprise hit movie starring Keanu...   \n",
       "3  Who does John Wick face as he is called upon b...   \n",
       "4  What is the genre and main actor of the film \"...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [: 22\\nReview: John Wick is one of my favourit...   \n",
       "1  [: 11\\nReview: JOHN WICK is a rare example of ...   \n",
       "2  [: 6\\nReview: In 2014, a Keanu Reeves revenge ...   \n",
       "3  [: 5\\nReview: Iosef's uncle still has John Wic...   \n",
       "4  [: 21\\nReview: John Wick is an action film wit...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  John Wick stands out as a favorite recent year...         simple   \n",
       "1  Some examples of classic international films s...         simple   \n",
       "2                                          John Wick         simple   \n",
       "3  John Wick faces deadly assassins, numerous kil...         simple   \n",
       "4  The genre of the film 'John Wick' is action, a...         simple   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'john_wick_2.csv', 'row': 22, 'Rev...          True  \n",
       "1  [{'source': 'john_wick_1.csv', 'row': 11, 'Rev...          True  \n",
       "2  [{'source': 'john_wick_2.csv', 'row': 6, 'Revi...          True  \n",
       "3  [{'source': 'john_wick_2.csv', 'row': 5, 'Revi...          True  \n",
       "4  [{'source': 'john_wick_1.csv', 'row': 21, 'Rev...          True  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# commented the following code because has already run once and will mess up Langsmith\n",
    "\n",
    "dataset_name = \"John Wicks Dataset 3\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions about John Wicks movie reviews\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "\n",
    "# client = Client()\n",
    "\n",
    "# dataset_name = \"AI Regulations Paragraph Chunks v3\"\n",
    "\n",
    "# dataset = client.create_dataset(\n",
    "#     dataset_name=dataset_name,\n",
    "#     description=\"Questions about AI regulations\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = naive_retrieval_chain.invoke({\"question\" : question})\n",
    "  answers.append(response[\"response\"].content)\n",
    "  contexts.append([context.page_content for context in response[\"context\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What makes John Wick stand out as a favorite recent years action movie?',\n",
       " 'answer': \"John Wick stands out as a favorite recent years action movie due to its slickness, the brilliance in its action sequences, Keanu Reeves' performance as the titular character, the Tarantino-esque dialog mixed with the swagger of action stars from the 70s, the well-paced and meticulously choreographed action scenes, and the overall fun and intense experience it provides viewers. The film is praised for its straightforward plot, clear motives, practical stunt work, lack of shaky cams or quick cuts, and the ability to deliver on what action fans want.\",\n",
       " 'contexts': [\": 9\\nReview: At first glance, John Wick sounds like a terrible film on paper but with the slickness of Keanu Reeves' performance as the titular character and the sheer brilliance in its action sequences, this marks the best action film of the year and one of the absolute best in the past decade. Following a brutal home invasion that leaves his beloved dog murdered by thugs from his past, John Wick vows revenge on the ones who have taken what he loves most. Like I said, on paper, this seems like a direct-to-DVD slopfest starring John Cena but as a film with Keanu Reeves as the lead, it marks the very welcomed return for Reeves to the genre. John Wick is insanely fun, violently brutal and an overall romp especially for those disappointed by The Expendables 3. John Wick is propelled by Tarantino-esque dialog mixed with the swagger of action stars from the 70s. Reeves literally emulates cool in this film and does it with such confidence, that we don't even doubt the character...even when he kills countless bad guys with extreme force in some utterly ridiculous and implausible situations. We don't doubt it for a minute. This is EXACTLY what you want out of an action film. It is briskly paced, brilliantly shot and meticulously choreographed and keeps you wanting more and more. The supporting cast filled with the likes of John Legiuzamo, Ian McShane, and Willen Dafoe also keeps this film very interesting. These guys don't play good guys, hell, John Wick by traditional standards would be a bad guy in any other film. Every character is more ruthless than the next and pushes John Wick to be more ruthless than they are, creating a very cool dynamic between the character and the plot regarding the idea of how far is too far? However, don't expect some revelation from John Wick regarding the morality of bad and evil. This film wants you entertained and does so with brute force, it never lets up, not even for a second. One scene in particular that will have your blood pumping is a showdown between thugs and Wick in a nightclub. This action sequence remains the best in the film and will have you grasping your theater seat because of the sheer intensity of it. Overall, John Wick is slick, violent fun that turns into a remarkable, surprising film that will catch you off guard. It is THAT good. I highly recommend this film to action buffs especially but I'm sure those who just like a good movie will love it as well.\",\n",
       "  \": 20\\nReview: John Wick is something special. It takes as much time setting up elaborate action sequences as it does the world with which it all takes place in. And what a world it is. It reminds me of Millers Crossing and it is cooler than any other recent attempt at noir. We are shown a criminal underworld where, if you are connected, many powerful people know who you are and show you respect. John Wick was connected but he got out. He is the rare killer who has found peace, and he is grateful for that peace. Some young kids steal that from him and he does what he does best, he wages a one man war against the Russian Mafia. It might sound like the film takes quite a leap but it all makes sense. The motives of John and the people who get in the way of his bullets are all very clear, even if it does come across as rather simple. That's the plot at it's most basic. Then there's the action. The film is directed by Reeve's stuntman from The Matrix, so this guy knows action. There are sequences that flow so smoothly it puts other action films and their quick cuts to shame. Keaunu moves so fluidly throughout the film and comes across as such a natural that the only disappointment is that we have not seen him like this before. Along the way are plenty of character actors, fans of The Matrix and The Wire will recognize a few people then there are more obvious ones like Ian McShane and Willem Dafoe. Everyone seems to be having a good time. That is another plus for this movie. It get's dark at times but overall it is quite fun, not very chipper, but fun. I cannot recommend this movie enough. I believe it is a must see for action fans and for anyone looking for something a bit different from the usual fare.\",\n",
       "  ': 5\\nReview: The first John Wick film was special because it broke a mold of sorts. It went against certain action film conventions - the hero was not a muscle bound hulk like a Schwarzenegger or Stallone, the action was super fast paced, the plot was basic and straighforward, but introduced some unique elements, and there was something a bit unique and stylish about the film. John Wick was cool.',\n",
       "  \": 7\\nReview: John Wick (2014) is the best revenge flick from Keanu Reeves of 2014 from The Matrix (1999) to John Wick (2014) another action fast paced, Entertaining slick action packed film, which kind I have never seen before. It is a very fun, straightforward action movie with an 80's sensibility. It's nice to see Keanu doing these types of roles again. It is one of my personal favorite Keanu Reeves movies. Keanu Reeves is a bad ass what a great action packed blood packed film. Movies should really learn from this on how to make a decent action film, especially with the crap we are getting today like escape plan bullet to the head and such. This film to me is the greatest action film to come out in this century. Keanu was phenomenal the action was so fast paced and exciting my jaw literally dropped as Keanu took out all the bad guys! I personally think this film is better then all Taken films combined. It was simply brilliant, it was made for 20 million dollars and I am glad it made 40 million in the US. I think this film deserved to make 100 million!\",\n",
       "  ': 22\\nReview: John Wick is one of my favourite recent years action movie and the second one pick up right where the first one left. The action is sharp, well filmed, no bad shaky cams and jump cuts like a certain bad action movie i saw recently. Its so refreshing to see everything and admire the practical stunt work.',\n",
       "  ': 3\\nReview: John wick has a very simple revenge story. It can be summarized as \"Keanu gets angry and shoots bad guys\" but what makes it special? Directed by Chad Stahelski who\\'s a stunt specialist boy does it show because the main selling point in the film are some real virtuoso action sequences, well made choreographies. Unlike today\\'s action movies, it doesn\\'t use quick-cuts or shaky cameras actually see what\\'s going on.',\n",
       "  \": 16\\nReview: John Wick 3 is without a doubt the best action movie to have come out in a few years. And its so surprising and refreshing to see that movies like this still exist. Most action movies you see is filled with ridiculous amounts of shaky-cam, fast edits and way over-the-top fights. This is perfect. You can see all action clear as day, and by god the stuns in this film are extraordinary. Why the Academy Awards don't award talent like this is beyond me. There were times that I wondered if they had used CGI, because someone nuts must be willing to throw themselves from motorbikes and through glass. But whatever case it is, its a dam joy to watch.\",\n",
       "  \": 11\\nReview: JOHN WICK is a rare example of Hollywood getting things spot-on when it comes to creating the near-perfect action film. JOHN WICK is a relentless, pulse-pounding thriller that has plenty of similarity to the Liam Neeson classic TAKEN, albeit with a more simplistic (and also more emotionally intense) plot line. This is the kind of lean, pared-down film-making that's all about intensity and momentum. It sits well with classic international fare like POINT BLANK, SLEEPLESS NIGHT, MEA CULPA, THE MAN FROM NOWHERE, and THE RAID films.\",\n",
       "  \": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\",\n",
       "  \": 6\\nReview: John Wick is one of those few movies a year that seemed like it would be absolutely terrible, but when you finally sit down and watch it, turns out to be incredible. Not only is it one of the most fun films of the year, but it's so much different than the action films we have today. It doesn't try to be inventive or over-the-top, it just plays to it's strengths.\"],\n",
       " 'ground_truth': 'John Wick stands out as a favorite recent years action movie due to its sharp and well-filmed action sequences, absence of shaky cams and jump cuts, and the opportunity to appreciate the practical stunt work involved.'}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "def run_evaluation(retrieval_chain):\n",
    "    answers = []\n",
    "    contexts = []\n",
    "\n",
    "    for question in test_questions:\n",
    "        response = retrieval_chain.invoke({\"question\" : question})\n",
    "        answers.append(response[\"response\"].content)\n",
    "        contexts.append([context.page_content for context in response[\"context\"]])\n",
    "    response_dataset = Dataset.from_dict({\n",
    "        \"question\" : test_questions,\n",
    "        \"answer\" : answers,\n",
    "        \"contexts\" : contexts,\n",
    "        \"ground_truth\" : test_groundtruths\n",
    "    })\n",
    "    return evaluate(response_dataset, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5fef7076214cdea21d7af1dbc78e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"Naive Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_naive():\n",
    "    return run_evaluation(naive_retrieval_chain)\n",
    "\n",
    "naive_results = run_naive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9333, 'answer_relevancy': 0.9664, 'context_recall': 1.0000, 'context_precision': 0.9599, 'answer_correctness': 0.8131}"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f506e17471b646c9a010cccf864ebebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"BM25 Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_bm25():\n",
    "    return run_evaluation(bm25_retrieval_chain)\n",
    "\n",
    "bm25_results = run_bm25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9600, 'answer_relevancy': 0.9525, 'context_recall': 1.0000, 'context_precision': 0.9833, 'answer_correctness': 0.7621}"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=naive_retriever\n",
    ")\n",
    "\n",
    "contextual_compression_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7957dc57b18d453da2b27b3c33db4ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "compressor = LLMChainExtractor.from_llm(chat_model)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=naive_retriever\n",
    ")\n",
    "compression_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"Context Compression Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_compression():\n",
    "    return run_evaluation(compression_retrieval_chain)\n",
    "\n",
    "compression_results = run_compression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8000, 'answer_relevancy': 0.9747, 'context_recall': 1.0000, 'context_precision': 0.7640, 'answer_correctness': 0.8572}"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=naive_retriever, llm=chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98dd6b612e4424793e24682146c432a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"Multiquery Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_multi_query():\n",
    "    return run_evaluation(multi_query_retrieval_chain)\n",
    "\n",
    "multi_query_results = run_multi_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9000, 'answer_relevancy': 0.9735, 'context_recall': 1.0000, 'context_precision': 0.9187, 'answer_correctness': 0.8590}"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "parent_docs = documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"full_documents\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "parent_document_vectorstore = Qdrant(\n",
    "    collection_name=\"full_documents\", \n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), \n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore = parent_document_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_document_retriever.add_documents(parent_docs, ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_document_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f73e39d0ee940c2b5bc6bf4391ca996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"Parent Document Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_parent_query():\n",
    "    return run_evaluation(parent_document_retrieval_chain)\n",
    "\n",
    "parent_results = run_parent_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8300, 'answer_relevancy': 0.9619, 'context_recall': 0.8667, 'context_precision': 1.0000, 'answer_correctness': 0.9760}"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, multi_query_retriever]\n",
    "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retriever_list, weights=equal_weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e1d6ff3e44a219228f63cda56e366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"Ensemble Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_ensemble_query():\n",
    "    return run_evaluation(ensemble_retrieval_chain)\n",
    "\n",
    "ensemble_results = run_ensemble_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'answer_relevancy': 0.9690, 'context_recall': 1.0000, 'context_precision': 0.9556, 'answer_correctness': 0.8916}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\"\n",
    ")\n",
    "semantic_documents = semantic_chunker.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_vectorstore = Qdrant.from_documents(\n",
    "    semantic_documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"JohnWickSemantic\"\n",
    ")\n",
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a4157036864be7957bad6a459d2d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "@traceable(\n",
    "        run_type=\"llm\",\n",
    "        name=\"OpenAI Call Decorator\",\n",
    "        project_name=f\"Semantic Naive Retrieval - {unique_id}\"\n",
    ")\n",
    "def run_semantic_naive():\n",
    "    return run_evaluation(semantic_retrieval_chain)\n",
    "semantic_results = run_semantic_naive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9000, 'answer_relevancy': 0.9762, 'context_recall': 0.9333, 'context_precision': 0.7698, 'answer_correctness': 0.8782}"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
